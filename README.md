# PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments

<img src="img/Logo.png" alt="Logo" style="zoom: 45%;" />

<div align="center"><img src="https://img.shields.io/badge/Version-1.0--alpha-brightgreen"> </div>

## ğŸŒ Introduction

ğŸš€ **PhysLab is the first video dataset for visual parsing of physics experimental processes!**

ğŸš€ **We provide rich multi-level annotations to support diverse computer vision research!**

ğŸš€ **Benchmark results on eight core vision tasks are established for comparison and reference!**

## ğŸ” Temporal Parsing

### ğŸ“¸ Annotation Samples

<p align="center">
  <img src="img/Fig. 1.jpg" alt="Dataset Overview" width="1000">
</p>

### ğŸ“ Statistics

The PhysLab dataset contains 620 long videos of four physical experiments, covering 3873 action clips of 32 types of actions, with an average length of 20 seconds per clip and a video frame rate of 30FPS. It subset provides valuable resources for video temporal research such as temporal action proposal, action classification, action alignment, and action segmentation.

<p align="center">
  <img src="img/Fig. 5-1.svg" alt="Dataset Overview" width="450">
  <img src="img/Fig. 5-2.svg" alt="Dataset Overview" width="465">
</p>

### ğŸ”§ Experimental Results

- **Temporal Action Proposal**

- **Action Classification**

- **Action Alignment & Action Segmentation**

## ğŸ” Spatial Parising

### ğŸ“¸ Annotation Samples

 <img src="img/intro.jpg" alt="å›¾4-1" style="zoom: 25%;" />

 <img src="img/Fig. 3.jpg" alt="å›¾4-1" style="zoom: 5%;" />
  
### ğŸ“ Statistics

### ğŸ”§ Experimental Results

- **Object Detection**

- **Occlusion Detection**

- **Instance Segmentation**

- **Human-Object Interaction Detection**

## ğŸ“£ Note

At present, we have completely completed the annotation of action classification, temporal action detection, action recognition, object detection, occlusion detection, human-object interaction detection, and instance segmentation related research. The annotation of visual text alignment is still in progress. We will release and provide benchmark performance in a timely manner.

At present, we are integrating multiple types of annotations and achieving accurate alignment between them. We have provided some samples for reference. The complete data is expected to be released within three months. Please continue to follow our dynamics.

At present, we are supplementing data samples of six other experimental types and building collection devices for chemical and biological experiments.

## ğŸ“¥ Download

## ğŸ‘ª Team

## âš ï¸ Disclaimer

The physical experiment dataset provided by this project is collected and annotated based on specific experimental scenarios and methods, but the dataset may contain a certain degree of deviation, incompleteness or erroneous information. Therefore, this dataset is for reference and research purposes only, and its absolute accuracy and applicability are not guaranteed. The results of analysis, modeling or other research activities using this dataset may contain errors or deviations and cannot be directly used for practical applications or decision-making. This project is not responsible for any consequences or losses arising from the use of the dataset. Users should bear their own risks when using the dataset and conduct necessary verification and validation of the data and research results.


